{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helper_functions as hf\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets,transforms\n",
    "from torchinfo import summary\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "REBUILD_DATA = False\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.walk_through_dir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_list = list(data_path.glob('*/*/*.jpg'))\n",
    "len(path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PIL.Image.open(random.choice(path_list))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COLOR_CHANNELS = 3\n",
    "IMG_SIZE = 128"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Image Normalization\n",
    "\n",
    "The values of mean and standard deviation of the training set are [0.4883, 0.4553, 0.4170],[0.2229, 0.2182, 0.2185]\n",
    "\n",
    "Run the below cell if you want to calculate the mean and standard deviation again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Run this cell to calculate mean and deviation of color\n",
    "# # Calculate mean and deviation of color\n",
    "# data_tranformer = transforms.Compose([\n",
    "#     transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "#     transforms.ToTensor()\n",
    "# ])\n",
    "\n",
    "# train_dataset = datasets.ImageFolder(root=data_path / \"train\", transform=data_tranformer)\n",
    "# test_dataset = datasets.ImageFolder(root=data_path / \"test\", transform=data_tranformer)\n",
    "# complete_dataset = torch.utils.data.ConcatDataset([train_dataset, test_dataset])\n",
    "\n",
    "# # Calculate mean image\n",
    "# mean_color = torch.zeros(COLOR_CHANNELS)\n",
    "# std_color = torch.zeros(COLOR_CHANNELS)\n",
    "\n",
    "# for image, _ in tqdm(complete_dataset):\n",
    "#     mean_color += image.mean(dim=(1,2)) # Mean of each channel\n",
    "#     std_color += image.std(dim=(1,2)) # Std of each channel\n",
    "    \n",
    "# mean_color = mean_color / len(complete_dataset) # Mean of all images\n",
    "# std_color = std_color / len(complete_dataset) # Std of all images\n",
    "\n",
    "# print(f\"Mean color: {mean_color}\")\n",
    "# print(f\"Std color: {std_color}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_data_tranformer = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.4883, 0.4553, 0.4170],[0.2229, 0.2182, 0.2185]),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(root=data_path / \"train\",transform=normalized_data_tranformer)\n",
    "test_dataset = datasets.ImageFolder(root=data_path / \"test\", transform=normalized_data_tranformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset[0][0].shape, train_dataset[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = train_dataset.classes\n",
    "CLASSES"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After normalization pixel values are in the range of [-1, 1]. Hence the images have bad contrast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, label = random.choice(train_dataset)\n",
    "print(image.shape, CLASSES[label])\n",
    "plt.imshow(image.permute(1, 2, 0), cmap='gray')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creat data loader\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "class TinyVGG(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=10, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            nn.BatchNorm2d(10)\n",
    "        )\n",
    "        \n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), \n",
    "            nn.BatchNorm2d(10)\n",
    "        )\n",
    "        \n",
    "        self.conv_block_3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=10, out_channels=10, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2), \n",
    "            nn.BatchNorm2d(10)\n",
    "        )\n",
    "        \n",
    "        self.Classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(2560, 2)\n",
    "        )\n",
    "                    \n",
    "    def forward(self, x):\n",
    "        return self.Classifier(self.conv_block_3(self.conv_block_2(self.conv_block_1(x))))\n",
    "    \n",
    "    \n",
    "class CatVsDog_2M(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "        self.conv_block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=5, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2),\n",
    "            \n",
    "            nn.BatchNorm2d(256)\n",
    "        )\n",
    "        \n",
    "        self.Classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 2),\n",
    "            # nn.Softmax(dim=1)\n",
    "        )\n",
    "                    \n",
    "    def forward(self, x):\n",
    "        return self.Classifier(self.conv_block(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TinyVGG()\n",
    "summary(model, input_size=(1, 3, 128, 128))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overfitting to a single batch of data is good practice to check if the model is working properly.\n",
    "If model can't overfit a single batch then there is something wrong with the model.\n",
    "\n",
    "Run for about 10 epochs and final loss must be less than 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overfit on a single batch\n",
    "overfit_model = CatVsDog_2M().to(device)\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "overfit_model_optimizer = torch.optim.Adam(overfit_model.parameters(), lr=0.0005)\n",
    "final_loss = hf.overfit_single_batch(overfit_model, train_loader, loss_fn, overfit_model_optimizer, epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config\n",
    "print(\"Using device:\" + device)\n",
    "\n",
    "EPOCHS = 10\n",
    "test_every = 5\n",
    "\n",
    "train_losses = []\n",
    "train_accuracies = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trigger training\n",
    "train_losses, test_losses = hf.train_model(model, train_loader, test_loader, loss_fn, optimizer, device, EPOCHS, test_every=test_every)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot loss curve\n",
    "hf.plot_loss_curve(train_losses, test_losses, every_n=test_every)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "torch.save(model.state_dict(), f\"model_cats_vs_dogs_1M.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "# model.load_state_dict(torch.load(\"model_cats_vs_dogs_1M.pth\"))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Model\n",
    "hf.show_random_prediction(model, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = hf.predict(model, test_dataset, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hf.plot_metrics(test_dataset.targets, predictions, test_dataset.classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
